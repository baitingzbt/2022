---
layout: default
---

<figure>
    <center><img src="https://offline-rl.github.io/assets/OFFLINE_RL.gif" style="width:65%"; /></center>
    <figcaption style='text-align: center'><small>Source: <a href="https://ai.googleblog.com/2020/04/an-optimistic-perspective-on-offline.html">Google AI Blog </a></small></figcaption>
</figure>

<div class="row">

<p>
Offline reinforcement learning (RL) is a re-emerging area of study that aims to learn behaviors using only logged data, such as data from previous experiments or human demonstrations, without further environment interaction. It has the potential to make tremendous progress in a number of real-world decision-making problems where active data collection is expensive (<span><em>e.g.,</em></span> in robotics, drug discovery, dialogue generation, recommendation systems) or unsafe/dangerous (<span><em>e.g.,</em></span> healthcare, autonomous driving, or education). Such a paradigm promises to resolve a key challenge to bringing reinforcement learning algorithms out of constrained lab settings to the real world. 
</p>

<p>
The <a href=https://offline-rl-neurips.github.io/> 1<sup>st</sup> offline RL workshop</a>, held at NeurIPS 2020, focused on and led to algorithmic development in offline RL and garnered wide attention. This year, we propose to shift the focus from algorithm design to <b>bridging the gap between offline RL research and real-world offline RL</b>. Our aim is to create a space for discussion between researchers and practitioners on topics of importance for enabling offline RL methods in the real-world. We will encourage discussions and contributions around (but not limited to) the following topics that are important in the context of enabling real-world applications of offline RL methods:
</p>
<ul>
<li>Offline RL using datasets unrelated or loosely-related to the task of interest </li>
<li>Real-world domains and benchmarks for offline RL</li>
<li>Cross-validation, model selection and hyperparameter tuning in offline settings</li>
<li>Accelerating lifelong and continual learning via offline RL</li>
<li>Novel application domains for offline RL, <span><em>e.g.,</em></span> black-box optimization. </li>
<li>Beyond pessimistic offline RL algorithms: generalization and uncertainty quantification</li>
<li>Optimization, stability and learning dynamics of offline RL algorithms</li>
</ul>
</div>

<p>
The submission deadline is October 6, 2021 (Anywhere on Earth). Please refer to the <a href="https://offline-rl-neurips.github.io/2021/submit.html"> submission </a> page for more details.
</p>
	
<div id="PC" class="row">
<h3>Program Committee</h3>
<div class="break"></div>
	<ul style="width:25%; float:left; display: inline; ">
		<li>Adam R Villaflor </li>
		<li>Alex Irpan </li>
		<li>Alex Lewandowski </li>
		<li>Anurag Ajay </li>
		<li>Ben London </li>
		<li>Biwei Huang </li>
		<li>Bo Dai </li>
		<li>Brandon Trabucco </li>
		<li>Canmanie T. Ponnambalam </li>
		<li>Chaochao Lu </li>
		<li>Cosmin Paduraru </li>
		<li>Daniel Seita </li>
		<li>David Krueger </li>
		<li>Dibya Ghosh </li>
		<li>Francesco Faccio </li>
		<li>Hadi Nekoei </li>
		<li>Homer R Walke </li>

	 </ul>

	<ul style="width:25%; float:center; display: inline; ">
		<li>Ilya Kostrikov </li>
		<li>Jacob Buckman </li>
		<li>Jiawei Huang </li>
		<li>Joey Hong </li>
		<li>Karush Suri </li>
		<li>Kevin Lu </li>
		<li>Konrad Zolna </li>
		<li>Ksenia Konyushova </li>
		<li>Luckeciano C Melo </li>
		<li>Masatoshi Uehara </li>
		<li>Ming Yin </li>
		<li>Oleh Rybkin </li>
		<li>Qiang He </li>
		<li>Rafael Rafailov </li>
		<li>Rahul Siripurapu </li>
		<li>Romina Abachi </li>
		<li>Ruosong Wang </li>
	</ul>

	<ul style="width:25%; float:right; display: inline;">
		<li>Kamyar Ghasemipour </li>
		<li>Shangtong Zhang </li>
		<li>Stephen Tian </li>
		<li>Taylor W Killian </li>
		<li>Tengyang Xie </li>
		<li>Thanh Nguyen-Tang </li>
		<li>Thomas L Paine </li>
		<li>Tianhe Yu </li>
		<li>Tianyuan Jin </li>
		<li>Yanan Wang </li>
		<li>Yevgen Chebotar </li>
		<li>Yi Su </li>
		<li>Yijie Guo </li>
		<li>Yue Wu </li>
		<li>Yuta Saito </li>
		<li>Yuwei Fu </li>
	</ul>
</div>

<div id="organizers" class="row">
<h2 style="float:left;">Organizers</h2>
<div class="break"></div>
<div style="text-align: left;">
{%- for person in site.data.organizers -%}
<div class="person">
  <img src="{{ person.image }}" height="170px" /><div style="height:12px;"></div>
   <a href="{{ person.url | relative_url }}">{{ person.name }}</a> <div style="height:4px;"></div>
   <span>{{ person.title | replace: '&', '<div style="height:4px;"></div>' }}</span>
</div>
{%- endfor -%}
</div>
</div>
<p> To contact the organizers, please send an email to <a href="mailto:offline-rl-neurips@google.com">offline-rl-neurips@google.com</a>. <p>


<p style="text-align:right">
  <small> Thanks to Jessica Hamrick for allowing us to borrow this <a href="https://baicsworkshop.github.io/index.html">template</a>. </small> </p>
