CMT_Paper_ID,Paper_Title,Authors_Name (comma separated),Link_to_Video,Camera Ready (Google Drive),Poster Links (Google Drive) [.png/.jpg]
4,DCUR: Data Curriculum for Teaching via Samples with Reinforcement Learning,"Daniel Seita, Abhinav Gopal, Zhao Mandi, John Canny",,https://drive.google.com/file/d/1OJ2MN6poHTMMHnUwaDGJhsIT5OUPtbs0/view?usp=sharing,
5,What Matters in Learning from Offline Human Demonstrations for Robot Manipulation,"Ajay Mandlekar, Danfei Xu, Josiah Wong, Soroush Nasiriany, Chen Wang, Rohun Kulkarni, Li Fei-Fei, Silvio Savarese, Yuke Zhu, Roberto Martín-Martín",https://youtu.be/dBcgEa3FpaA,https://drive.google.com/file/d/1lZyjkkNJu2NORMKI1tfWuREP5vrBaaLx/view?usp=sharing,https://drive.google.com/file/d/1q2p1Gz17gdCJXX0MNDu_BrKVcDAsro5N/view?usp=sharing
6,TiKick: Towards Playing Multi-agent Football Full Games from Single-agent Demonstrations,"Shiyu Huang, Wenze Chen, Longfei Zhang, Shizhen Xu, Ziyang Li, Fengming Zhu, Deheng Ye, Ting Chen, Jun Zhu",https://drive.google.com/file/d/1fTuPbPZVCZkPSQ7gn-hdtXMvxtHrylQl/view?usp=sharing,https://drive.google.com/file/d/1KDGyLzF-B-7q5MH9DmUWcmnCS_84Qt57/view?usp=sharing,https://drive.google.com/file/d/1ixLvXE89bJrRwL3okJPL0IuBl2Yx4slI/view?usp=sharing
7,d3rlpy: An Offline Deep Reinforcement Learning Library,"Takuma Seno, Michita Imai",https://www.youtube.com/watch?v=NcOqY5djZ3s,https://drive.google.com/file/d/1G6cuhu7aRxo1Mi3INCxWGY7T7QRJzP6c/view?usp=sharing,
9,PulseRL: Enabling Offline Reinforcement Learning for Digital Marketing Systems via Conservative Q-Learning,"Luckeciano Melo*, Luana Martins*, Bryan Oliveira*, Bruno Brandao*, Douglas Soares, Telma Lima ",https://recorder-v3.slideslive.com/?share=55195&s=31ee83a3-6e6f-4c23-ae2d-512b7d08350f,https://drive.google.com/file/d/1WupTq5Jm4IQll6I3w9JUAHiMVSqbB90s/view?usp=sharing,
11,Domain Knowledge Guided Offline Q Learning,"Xiaoxuan Zhang, Sijia Zhang, Yen-Yun Yu",,https://drive.google.com/file/d/1J17PpJi7Yf_WQjRqKJP06MNO3FcquXZV/view?usp=sharing,
12,Understanding the Effects of Dataset Characteristics on Offline Reinforcement Learning,"Kajetan Schweighofer, Markus Hofmarcher, Marius-Constantin Dinu, Philipp Renz, Angela Bitto-Nemling, Vihang Patil, Sepp Hochreiter",https://recorder-v3.slideslive.com/?share=54252&s=8437e42b-a0ea-4669-8760-972c96b75900,https://drive.google.com/file/d/114sMSyhEZJNGFkP9Mn3Xx9wWPqtgQGvS/view?usp=sharing,https://drive.google.com/file/d/16p-X1HetGW3MPRAby8Uurwbmav2HLFON/view?usp=sharing
14,Counter-Strike Deathmatch with Large-Scale Behavioural Cloning,"Tim Pearce, Jun Zhu",https://youtu.be/cebTNNCoINA,https://drive.google.com/file/d/1-Jc4coENnPbPcq17onrk4degPktPuI8i/view?usp=sharing,https://drive.google.com/file/d/1-Pofufw-YU-8umKNzRe3K0c1KiBW70GC/view?usp=sharing
15,Modern Hopfield Networks for Sample-Efficient Return Decomposition from Demonstrations,"Michael Widrich, Markus Hofmarcher, Vihang Patil, Angela Bitto-Nemling, Sepp Hochreiter",https://youtu.be/RXCWyWpg5YE,https://drive.google.com/file/d/1Ugl-7xFpfMSffC0ZBqWor6_FlCQVHBCC/view?usp=sharing,https://drive.google.com/file/d/1dN2a40x89ysDe3PXKn6xlTv7TN4uKLRB/view?usp=sharing
16,Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage,"Masatsohii Uehara, Wen Sun ",https://drive.google.com/file/d/1zMtyOniwGhqr_0mdwGuhqEOCe0MxWeGC/view?usp=sharing,https://drive.google.com/file/d/1zMtyOniwGhqr_0mdwGuhqEOCe0MxWeGC/view?usp=sharing,
17,Importance of Representation Learning for Off-Policy Fitted Q-Evaluation,"Xian Wu, Nevena Lazic, Dong Yin, Cosmin Paduraru",https://drive.google.com/file/d/1KGX9BobofXE8KoCpIcBIZTGCfqHYU-iY/view?usp=sharing,https://drive.google.com/file/d/1kuokAmehZkTs6pMNawRVYeHdDLM0O3p2/view?usp=sharing,
18,Offline Contextual Bandits for Wireless Network Optimization,"Miguel Suau, Alexandros Agapitos, David Lynch, Derek Farrell, Mingqi Zhou, and Aleksandar Milenovic",https://youtu.be/yfBqyzqhnPQ,https://drive.google.com/file/d/1u70NrxCLgXlRTZGfoGxMczRE4Du0f4pC/view?usp=sharing,https://drive.google.com/file/d/123j0JW6I0E7I3-O_gFyH58l0P606r_hl/view?usp=sharing
19,Robust On-Policy Data Collection for Data-Efficient Policy Evaluation,"Rujie Zhong, Josiah P. Hanna, Lukas Schäfer, Stefano V. Albrecht",https://youtu.be/ZN3QflPtI-g,https://drive.google.com/file/d/1VXJhUat9wFi_6ObKhuypFAcq8mM7goZA/view,
21,Doubly Pessimistic Algorithms for Strictly Safe Off-Policy Optimization,"Sanae Amani, Lin F. Yang",https://drive.google.com/file/d/1cGsHxS8PtrDtpFcUiD0tGexw9QQMM3yI/view?usp=sharing,https://drive.google.com/file/d/1IACxiZSlqWcwZ5vi3X6LgFsio3FMbeVd/view?usp=sharing,https://drive.google.com/file/d/1ZNw6Ga_8w5H4C3VZ0dIBygPPVD4HUzoz/view?usp=sharing
22,Offline RL With Resource Constrained Online Deployment,"Jayanth Reddy Regatti, Aniket Anand Deshmukh, Frank Cheng, Young Hun Jung, Abhishek Gupta, Urun Dogan",,https://drive.google.com/file/d/1eprB4uj-0S8w6IMHoOl7vIb71Rx0molw/view?usp=sharing,
23,Personalization for Web-based Services using Offline Reinforcement Learning,"Pavlos A. Apostolopoulos, Zehui Wang, Hanson Wang, Chad Zhou, Kittipat Virochsiri, Norm Zhou, Igor L. Markov",,https://drive.google.com/file/d/1Bv9o8WRF3FQ1itOmc7enzRn5eRh4nLM2/view?usp=sharing,https://drive.google.com/file/d/1l8Q92tfL99_udArltSVIikXbuLQ5Y5G1/view?usp=sharing
25,Pessimistic Model Selection for Offline Deep Reinforcement Learning,"Chao-Han Huck Yang, Zhengling Qi, Yifang Cui, Pin-Yu Chen
",,https://drive.google.com/file/d/1hJB1brs28TIJilH_FcLrkXREz880N7_u/view?usp=sharing,https://drive.google.com/file/d/1ny6visgxKO-LVqEUP2gUGwj4QOSZbbv-/view?usp=sharing
26,BATS: Best Action Trajectory Stitching,"Ian Char*, Viraj Mehta*, Adam Villaflor, John M. Dolan, Jeff Schneider",,https://drive.google.com/file/d/1L5L74mmagvfCDGpTw42k1xa0dEfQTObu/view?usp=sharing,
27,Single-Shot Pruning for Offline Reinforcement Learning,"Samin Yeasar Arnob, Riyasat Ohib, Sergey Plis, Doina Precup",,https://drive.google.com/file/d/1huWwVKs-RMXIYVVJRU8nzBxjsHUHzKWV/view?usp=sharing,
28,"Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization","Thanh Nguyen-Tang, Sunil Gupta, A.Tuan Nguyen, Svetha Venkatesh",,https://drive.google.com/file/d/1NLTCVGxCCmeOwv7niAgpwFGGm9BmnsqS/view,
29,Improving Zero-shot Generalization in Offline Reinforcement Learning using Generalized Similarity Functions,"Bogdan Mazoure, Ilya Kostrikov, Ofir Nachum, Jonathan Tompson",https://youtu.be/MDWoAbK4G0g,https://drive.google.com/file/d/1-I0rDZaDY93zKAXW8wDidmLR_VAG85cx/view?usp=sharing,
29,Offline Meta-Reinforcement Learning for Industrial Insertion,"Tony Z. Zhao*, Jianlan Luo*, Oleg Sushkov, Rugile Pevceviciute, Nicolas Heess, Jon Scholz, Stefan Schaal, Sergey Levine",,https://drive.google.com/file/d/1khF2vpkJgaATZbfpjUHB1GwQhHuuJI0q/view?usp=sharing,
30,Adaptive Behavior Cloning Regularization for Stable Offline-to-Online Reinforcement Learning,"Yi Zhao, Rinu Boney, Alexander Ilin, Juho Kannala, Joni Pajarinen",https://drive.google.com/file/d/14GE4nXHp1fK4iThBx-p0Kfc2UqTSp_uu/view?usp=sharing,https://drive.google.com/file/d/1yWXvoQmJxLvhmLe7GmaqDpWr0BLP_Lp4/view?usp=sharing,
31,What Would the Expert do?: Causal Imitation Learning,"Gokul Swamy, Sanjiban Choudhury, Drew Bagnell, Steven Wu",https://www.youtube.com/watch?v=LcTXrxYc2fg,https://drive.google.com/file/d/1tuIrG1CGXjm1-tMeA2mNi78QORDQuzS2/view?usp=sharing,https://drive.google.com/file/d/1XvSzs84sY9UwKbgNFjznbll2OwBzaXE0/view?usp=sharing
32,Quantile Filtered Imitation Learning,"David Brandfonbrener, William Whitney, Rajesh Ranganath, Joan Bruna",https://drive.google.com/file/d/1YDQzElq67FTDz4YAGtGKw_RumMgqNVYO/view?usp=sharing,https://drive.google.com/file/d/1klSZEGfrEVjG0N7JveVgXr9krXt0ohjb/view?usp=sharing,https://drive.google.com/file/d/147G2iDpfJpkncgpqwn8m8M7MNw9XZ8cA/view?usp=sharing
33,Benchmarking Sample Selection Strategies for Batch Reinforcement Learning,"Yuwei Fu, Di Wu, Benoit Boulet",https://drive.google.com/file/d/1P0YRvi3B115oF2SX1oaalK3qYLW0Iplc/view?usp=sharing,https://drive.google.com/file/d/1I8rad5mojF3lCyDNlvF9Dwgs4hESFF-_/view?usp=sharing,https://drive.google.com/file/d/19VuBugRN4elVQkV9CWzOW7lBhp4x9020/view?usp=sharing
34,Dynamic Mirror Descent based Model Predictive Control for Accelerating Robot Learning,"Utkarsh A. Mishra*, Soumya R. Samineni*, Prakhar Goel, Chandravaran Kunjeti, Himanshu Lodha, Aman Singh, Aditya Sagi, Shalabh Bhatnagar, Shishir Kolathaya",https://drive.google.com/file/d/1-hw1bclZHfED8wheRjnpKbJhRpSd1MsU/view?usp=sharing,https://drive.google.com/file/d/1rS_C3s6fSkehQZWi5SQByq1bRuKvH-j4/view?usp=sharing,https://drive.google.com/file/d/1QMnWS5Kq-jQv7yrv8mCd6Ai-5xe1Pf-s/view?usp=sharing
35,MBAIL: Multi-Batch Best Action Imitation Learning utilizing Sample Transfer and Policy Distillation,"Di Wu, Tianyu Li, David Meger, Michael Jenkin, Xue Liu, Gregory Dudek",,https://drive.google.com/file/d/1tjrfvY9Ehmmas7Wg7WKn5F0CA0bc_aIe/view?usp=sharing,
36,"Showing Your Offline Reinforcement Learning Work:
Online Evaluation Budget Matters","Vladislav Kurenkov, Sergey Kolesnikov",https://drive.google.com/file/d/1W12JEwiYEgUNUQQ4Uj1lwOM86_IKsdah/view?usp=sharing,https://drive.google.com/file/d/1Np4QR13o92J2VRJzsi6v-gfwA2La87vA/view?usp=sharing,
37,Offline Reinforcement Learning with Munchausen Regularization,"Hsin-Yu Liu, Balaji Bharathan, Rajesh Gupta, Dezhi Hong",https://drive.google.com/file/d/1aHsqNk3YiDJqsY1pSgsQBvJgWy3UefvN/view?usp=sharing,https://drive.google.com/file/d/1qkEn_iQu60Z833Kq8Uwc2ha6ZtowbGEm/view?usp=sharing,https://drive.google.com/drive/folders/1f3s968srHW_aQ0gG6G9mHGV6UheEphU2?usp=sharing
38,"Importance of Empirical Sample Complexity Analysis
for Offline Reinforcement Learning","Samin Yeasar Arnob, Riashat Islam, Doina Precup",,https://drive.google.com/file/d/1D05pnuLpsRwCqH9384sUMG8K3H3j3hJz/view?usp=sharing,
39,Discrete Uncertainty Quantification Approach for Offline RL,"Javier Corrochano, Javier García, Rubén Majadas, Cristina Ibanez-Llano, Sergio Pérez, Fernando Fernández",https://youtu.be/u-5OmCH2pp8,https://drive.google.com/file/d/1G5nAFVQlXAlVjBwo85hCACt6Or2hnO4D/view?usp=sharing,https://drive.google.com/file/d/1qPve8aRfDDN9ZPkUzji9hKmcGAPQTXnT/view?usp=sharing
40,Pretraining For Language-Conditioned Imitation with Transformers,"Aaron (Louie) Putterman, Kevin Lu, Igor Mordatch, Pieter Abbeel",,https://drive.google.com/file/d/1D79NZ7lh_te9BCHRldD8eVJYqAFuFabH/view?usp=sharing,
41,"Stateful Offline Contextual Policy Evaluation and Learning
","Nathan Kallus, Angela Zhou",,https://drive.google.com/file/d/1LIM0ITSVIo_8Hp_BhquKDx02lEDCPc3O/view?usp=sharing,https://drive.google.com/file/d/13hs5B_HIBftyYX0qCqPAh_iPczTINQyK/view?usp=sharing
42,Offline Reinforcement Learning: Fundamental Barriers for Value Function Approximation,"Dylan Foster, Akshay Krishnamurthy, David Simchi-Levi, Yunzong Xu",,https://drive.google.com/file/d/1C6M1peNbobhd2vTRYYbGQATsUvkEMEDm/view?usp=sharing,
43,Learning Value Functions from Undirected State-only Experience,"Matthew Chang*, Arjun Gupta*, Saurabh Gupta",https://slideslive.com/38971128/learning-value-functions-from-undirected-stateonly-experience,https://drive.google.com/file/d/1ejlJYYeZ4o9SGFjKco8SFZ7uANw2-ldV/view?usp=sharing,https://drive.google.com/file/d/1SoruropIEE5IZge9u3KdJeyjcpJ5a2-N/view?usp=sharing
44,Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations,"Haoran Xu, Xianyuan Zhan, Honglei Yin, Huiling Qin",https://recorder-v3.slideslive.com/?share=53264&s=79e721fe-5da9-4006-89a8-70b2ef8a4586,,
45,Offline Policy Selection under Uncertainty,"Sherry Yang, Bo Dai, Ofir Nachum, George Tucker, Dale Schuurmans",,,https://drive.google.com/file/d/1BDAr5ShV85Y7e_xgZ401FGBV9htMe3m_/view?usp=sharing
46,Model-Based Offline Planning with Trajectory Pruning,"
Xianyuan Zhan, Xiangyu Zhu, Haoran Xu",https://drive.google.com/file/d/1n5l9pBNGj3780cUZ4zbjE_8OgroCdPoU/view?usp=sharing,https://drive.google.com/file/d/1TCs53FEmXl_BNzg9SByWkFgaFjsugA6J/view?usp=sharing,https://docs.google.com/presentation/d/1QarbyqGObkpeWgPbeW_bPcwPIWTtlwBL/edit?usp=sharing&ouid=100893415177844711737&rtpof=true&sd=true
47,TRAIL: Near-Optimal Imitation Learning with Suboptimal Data,"Sherry Yang, Sergey Levine, Ofir Nachum",,https://drive.google.com/file/d/1YUKrdpLM4eZTSMcSZ6rn-cAb6BOHGbWT/view?usp=sharing,https://drive.google.com/file/d/1wzuQdNldtyadooasE8ZZfhZ4xCLzrt9k/view?usp=sharing
51,"Why so pessimistic? Estimating uncertainties for offline rl through ensembles, and why their independence matters","Seyed Kamyar Seyed Ghasemipour, Shixiang (Shane) Gu, Ofir Nachum",https://drive.google.com/file/d/1gbPtFhVyJ4FrW0gV7aFxdurcwPhKOWUH/view?usp=sharing,https://drive.google.com/file/d/1wrOWDPkQuLp89bv5qWZHImwWCBTsfV7c/view?usp=sharing,
53,Example-Based Offline Reinforcement Learning without Rewards,"Kyle Hatch*, Tianhe Yu*, Rafael Rafailov, Chelsea Finn",,https://drive.google.com/file/d/1K4hhEeljNGHjqdTz2NWsuLBPYeQwkqkV/view?usp=sharing,
